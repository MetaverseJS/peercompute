import {
  import_index
} from "./chunk-JWYNMUOX.js";
import {
  pTimeout
} from "./chunk-DO2DH4V2.js";
import {
  PeerMap,
  PeerSet
} from "./chunk-DIEVBDCT.js";
import {
  pbStream
} from "./chunk-O3N7UJNM.js";
import "./chunk-DKVXG43P.js";
import {
  peerIdFromMultihash,
  peerIdFromPrivateKey,
  peerIdFromPublicKey
} from "./chunk-7EPQD6JW.js";
import "./chunk-HJM7NZQ6.js";
import {
  InvalidMessageError,
  InvalidParametersError,
  MaxLengthError,
  NotStartedError,
  TypedEventEmitter,
  decodeMessage,
  encodeMessage,
  message,
  publicKeyFromProtobuf,
  publicKeyToProtobuf,
  randomBytes,
  serviceCapabilities,
  serviceDependencies
} from "./chunk-NTF5EBGJ.js";
import {
  concat,
  decode,
  fromString,
  sha256,
  toString
} from "./chunk-5QZ7JOES.js";
import {
  __privateAdd,
  __privateGet,
  __privateMethod,
  __privateSet,
  __privateWrapper,
  __publicField
} from "./chunk-WOOG5QLI.js";

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/constants.js
var pubSubSymbol = Symbol.for("@libp2p/pubsub");

// ../../peercompute/node_modules/@libp2p/floodsub/node_modules/p-queue/dist/lower-bound.js
function lowerBound(array, value, comparator) {
  let first = 0;
  let count = array.length;
  while (count > 0) {
    const step = Math.trunc(count / 2);
    let it = first + step;
    if (comparator(array[it], value) <= 0) {
      first = ++it;
      count -= step + 1;
    } else {
      count = step;
    }
  }
  return first;
}

// ../../peercompute/node_modules/@libp2p/floodsub/node_modules/p-queue/dist/priority-queue.js
var _queue;
var PriorityQueue = class {
  constructor() {
    __privateAdd(this, _queue, []);
  }
  enqueue(run, options) {
    const { priority = 0, id } = options ?? {};
    const element = {
      priority,
      id,
      run
    };
    if (this.size === 0 || __privateGet(this, _queue)[this.size - 1].priority >= priority) {
      __privateGet(this, _queue).push(element);
      return;
    }
    const index = lowerBound(__privateGet(this, _queue), element, (a, b) => b.priority - a.priority);
    __privateGet(this, _queue).splice(index, 0, element);
  }
  setPriority(id, priority) {
    const index = __privateGet(this, _queue).findIndex((element) => element.id === id);
    if (index === -1) {
      throw new ReferenceError(`No promise function with the id "${id}" exists in the queue.`);
    }
    const [item] = __privateGet(this, _queue).splice(index, 1);
    this.enqueue(item.run, { priority, id });
  }
  dequeue() {
    const item = __privateGet(this, _queue).shift();
    return item == null ? void 0 : item.run;
  }
  filter(options) {
    return __privateGet(this, _queue).filter((element) => element.priority === options.priority).map((element) => element.run);
  }
  get size() {
    return __privateGet(this, _queue).length;
  }
};
_queue = new WeakMap();

// ../../peercompute/node_modules/@libp2p/floodsub/node_modules/p-queue/dist/index.js
var _carryoverIntervalCount, _isIntervalIgnored, _intervalCount, _intervalCap, _rateLimitedInInterval, _rateLimitFlushScheduled, _interval, _intervalEnd, _lastExecutionTime, _intervalId, _timeoutId, _queue2, _queueClass, _pending, _concurrency, _isPaused, _idAssigner, _runningTasks, _PQueue_instances, doesIntervalAllowAnother_get, doesConcurrentAllowAnother_get, next_fn, onResumeInterval_fn, isIntervalPaused_get, createIntervalTimeout_fn, clearIntervalTimer_fn, clearTimeoutTimer_fn, tryToStartAnother_fn, initializeIntervalIfNeeded_fn, onInterval_fn, processQueue_fn, onEvent_fn, setupRateLimitTracking_fn, scheduleRateLimitUpdate_fn, updateRateLimitState_fn;
var PQueue = class extends import_index.default {
  constructor(options) {
    var _a2, _b2;
    super();
    __privateAdd(this, _PQueue_instances);
    __privateAdd(this, _carryoverIntervalCount);
    __privateAdd(this, _isIntervalIgnored);
    __privateAdd(this, _intervalCount, 0);
    __privateAdd(this, _intervalCap);
    __privateAdd(this, _rateLimitedInInterval, false);
    __privateAdd(this, _rateLimitFlushScheduled, false);
    __privateAdd(this, _interval);
    __privateAdd(this, _intervalEnd, 0);
    __privateAdd(this, _lastExecutionTime, 0);
    __privateAdd(this, _intervalId);
    __privateAdd(this, _timeoutId);
    __privateAdd(this, _queue2);
    __privateAdd(this, _queueClass);
    __privateAdd(this, _pending, 0);
    // The `!` is needed because of https://github.com/microsoft/TypeScript/issues/32194
    __privateAdd(this, _concurrency);
    __privateAdd(this, _isPaused);
    // Use to assign a unique identifier to a promise function, if not explicitly specified
    __privateAdd(this, _idAssigner, 1n);
    // Track currently running tasks for debugging
    __privateAdd(this, _runningTasks, /* @__PURE__ */ new Map());
    /**
        Get or set the default timeout for all tasks. Can be changed at runtime.
    
        Operations will throw a `TimeoutError` if they don't complete within the specified time.
    
        The timeout begins when the operation is dequeued and starts execution, not while it's waiting in the queue.
    
        @example
        ```
        const queue = new PQueue({timeout: 5000});
    
        // Change timeout for all future tasks
        queue.timeout = 10000;
        ```
        */
    __publicField(this, "timeout");
    options = {
      carryoverIntervalCount: false,
      intervalCap: Number.POSITIVE_INFINITY,
      interval: 0,
      concurrency: Number.POSITIVE_INFINITY,
      autoStart: true,
      queueClass: PriorityQueue,
      ...options
    };
    if (!(typeof options.intervalCap === "number" && options.intervalCap >= 1)) {
      throw new TypeError(`Expected \`intervalCap\` to be a number from 1 and up, got \`${((_a2 = options.intervalCap) == null ? void 0 : _a2.toString()) ?? ""}\` (${typeof options.intervalCap})`);
    }
    if (options.interval === void 0 || !(Number.isFinite(options.interval) && options.interval >= 0)) {
      throw new TypeError(`Expected \`interval\` to be a finite number >= 0, got \`${((_b2 = options.interval) == null ? void 0 : _b2.toString()) ?? ""}\` (${typeof options.interval})`);
    }
    __privateSet(this, _carryoverIntervalCount, options.carryoverIntervalCount ?? options.carryoverConcurrencyCount ?? false);
    __privateSet(this, _isIntervalIgnored, options.intervalCap === Number.POSITIVE_INFINITY || options.interval === 0);
    __privateSet(this, _intervalCap, options.intervalCap);
    __privateSet(this, _interval, options.interval);
    __privateSet(this, _queue2, new options.queueClass());
    __privateSet(this, _queueClass, options.queueClass);
    this.concurrency = options.concurrency;
    if (options.timeout !== void 0 && !(Number.isFinite(options.timeout) && options.timeout > 0)) {
      throw new TypeError(`Expected \`timeout\` to be a positive finite number, got \`${options.timeout}\` (${typeof options.timeout})`);
    }
    this.timeout = options.timeout;
    __privateSet(this, _isPaused, options.autoStart === false);
    __privateMethod(this, _PQueue_instances, setupRateLimitTracking_fn).call(this);
  }
  get concurrency() {
    return __privateGet(this, _concurrency);
  }
  set concurrency(newConcurrency) {
    if (!(typeof newConcurrency === "number" && newConcurrency >= 1)) {
      throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${newConcurrency}\` (${typeof newConcurrency})`);
    }
    __privateSet(this, _concurrency, newConcurrency);
    __privateMethod(this, _PQueue_instances, processQueue_fn).call(this);
  }
  /**
      Updates the priority of a promise function by its id, affecting its execution order. Requires a defined concurrency limit to take effect.
  
      For example, this can be used to prioritize a promise function to run earlier.
  
      ```js
      import PQueue from 'p-queue';
  
      const queue = new PQueue({concurrency: 1});
  
      queue.add(async () => 'ðŸ¦„', {priority: 1});
      queue.add(async () => 'ðŸ¦€', {priority: 0, id: 'ðŸ¦€'});
      queue.add(async () => 'ðŸ¦„', {priority: 1});
      queue.add(async () => 'ðŸ¦„', {priority: 1});
  
      queue.setPriority('ðŸ¦€', 2);
      ```
  
      In this case, the promise function with `id: 'ðŸ¦€'` runs second.
  
      You can also deprioritize a promise function to delay its execution:
  
      ```js
      import PQueue from 'p-queue';
  
      const queue = new PQueue({concurrency: 1});
  
      queue.add(async () => 'ðŸ¦„', {priority: 1});
      queue.add(async () => 'ðŸ¦€', {priority: 1, id: 'ðŸ¦€'});
      queue.add(async () => 'ðŸ¦„');
      queue.add(async () => 'ðŸ¦„', {priority: 0});
  
      queue.setPriority('ðŸ¦€', -1);
      ```
      Here, the promise function with `id: 'ðŸ¦€'` executes last.
      */
  setPriority(id, priority) {
    if (typeof priority !== "number" || !Number.isFinite(priority)) {
      throw new TypeError(`Expected \`priority\` to be a finite number, got \`${priority}\` (${typeof priority})`);
    }
    __privateGet(this, _queue2).setPriority(id, priority);
  }
  async add(function_, options = {}) {
    options.id ?? (options.id = (__privateWrapper(this, _idAssigner)._++).toString());
    options = {
      timeout: this.timeout,
      ...options
    };
    return new Promise((resolve, reject) => {
      const taskSymbol = Symbol(`task-${options.id}`);
      __privateGet(this, _queue2).enqueue(async () => {
        var _a2, _b2;
        __privateWrapper(this, _pending)._++;
        __privateGet(this, _runningTasks).set(taskSymbol, {
          id: options.id,
          priority: options.priority ?? 0,
          // Match priority-queue default
          startTime: Date.now(),
          timeout: options.timeout
        });
        let eventListener;
        try {
          try {
            (_a2 = options.signal) == null ? void 0 : _a2.throwIfAborted();
          } catch (error) {
            if (!__privateGet(this, _isIntervalIgnored)) {
              __privateWrapper(this, _intervalCount)._--;
            }
            __privateGet(this, _runningTasks).delete(taskSymbol);
            throw error;
          }
          let operation = function_({ signal: options.signal });
          if (options.timeout) {
            operation = pTimeout(Promise.resolve(operation), {
              milliseconds: options.timeout,
              message: `Task timed out after ${options.timeout}ms (queue has ${__privateGet(this, _pending)} running, ${__privateGet(this, _queue2).size} waiting)`
            });
          }
          if (options.signal) {
            const { signal } = options;
            operation = Promise.race([operation, new Promise((_resolve, reject2) => {
              eventListener = () => {
                reject2(signal.reason);
              };
              signal.addEventListener("abort", eventListener, { once: true });
            })]);
          }
          const result = await operation;
          resolve(result);
          this.emit("completed", result);
        } catch (error) {
          reject(error);
          this.emit("error", error);
        } finally {
          if (eventListener) {
            (_b2 = options.signal) == null ? void 0 : _b2.removeEventListener("abort", eventListener);
          }
          __privateGet(this, _runningTasks).delete(taskSymbol);
          queueMicrotask(() => {
            __privateMethod(this, _PQueue_instances, next_fn).call(this);
          });
        }
      }, options);
      this.emit("add");
      __privateMethod(this, _PQueue_instances, tryToStartAnother_fn).call(this);
    });
  }
  async addAll(functions, options) {
    return Promise.all(functions.map(async (function_) => this.add(function_, options)));
  }
  /**
  Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)
  */
  start() {
    if (!__privateGet(this, _isPaused)) {
      return this;
    }
    __privateSet(this, _isPaused, false);
    __privateMethod(this, _PQueue_instances, processQueue_fn).call(this);
    return this;
  }
  /**
  Put queue execution on hold.
  */
  pause() {
    __privateSet(this, _isPaused, true);
  }
  /**
  Clear the queue.
  */
  clear() {
    __privateSet(this, _queue2, new (__privateGet(this, _queueClass))());
    __privateMethod(this, _PQueue_instances, updateRateLimitState_fn).call(this);
  }
  /**
      Can be called multiple times. Useful if you for example add additional items at a later time.
  
      @returns A promise that settles when the queue becomes empty.
      */
  async onEmpty() {
    if (__privateGet(this, _queue2).size === 0) {
      return;
    }
    await __privateMethod(this, _PQueue_instances, onEvent_fn).call(this, "empty");
  }
  /**
      @returns A promise that settles when the queue size is less than the given limit: `queue.size < limit`.
  
      If you want to avoid having the queue grow beyond a certain size you can `await queue.onSizeLessThan()` before adding a new item.
  
      Note that this only limits the number of items waiting to start. There could still be up to `concurrency` jobs already running that this call does not include in its calculation.
      */
  async onSizeLessThan(limit) {
    if (__privateGet(this, _queue2).size < limit) {
      return;
    }
    await __privateMethod(this, _PQueue_instances, onEvent_fn).call(this, "next", () => __privateGet(this, _queue2).size < limit);
  }
  /**
      The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.
  
      @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.
      */
  async onIdle() {
    if (__privateGet(this, _pending) === 0 && __privateGet(this, _queue2).size === 0) {
      return;
    }
    await __privateMethod(this, _PQueue_instances, onEvent_fn).call(this, "idle");
  }
  /**
      The difference with `.onIdle` is that `.onPendingZero` only waits for currently running tasks to finish, ignoring queued tasks.
  
      @returns A promise that settles when all currently running tasks have completed; `queue.pending === 0`.
      */
  async onPendingZero() {
    if (__privateGet(this, _pending) === 0) {
      return;
    }
    await __privateMethod(this, _PQueue_instances, onEvent_fn).call(this, "pendingZero");
  }
  /**
  @returns A promise that settles when the queue becomes rate-limited due to intervalCap.
  */
  async onRateLimit() {
    if (this.isRateLimited) {
      return;
    }
    await __privateMethod(this, _PQueue_instances, onEvent_fn).call(this, "rateLimit");
  }
  /**
  @returns A promise that settles when the queue is no longer rate-limited.
  */
  async onRateLimitCleared() {
    if (!this.isRateLimited) {
      return;
    }
    await __privateMethod(this, _PQueue_instances, onEvent_fn).call(this, "rateLimitCleared");
  }
  /**
      @returns A promise that rejects when any task in the queue errors.
  
      Use with `Promise.race([queue.onError(), queue.onIdle()])` to fail fast on the first error while still resolving normally when the queue goes idle.
  
      Important: The promise returned by `add()` still rejects. You must handle each `add()` promise (for example, `.catch(() => {})`) to avoid unhandled rejections.
  
      @example
      ```
      import PQueue from 'p-queue';
  
      const queue = new PQueue({concurrency: 2});
  
      queue.add(() => fetchData(1)).catch(() => {});
      queue.add(() => fetchData(2)).catch(() => {});
      queue.add(() => fetchData(3)).catch(() => {});
  
      // Stop processing on first error
      try {
          await Promise.race([
              queue.onError(),
              queue.onIdle()
          ]);
      } catch (error) {
          queue.pause(); // Stop processing remaining tasks
          console.error('Queue failed:', error);
      }
      ```
      */
  // eslint-disable-next-line @typescript-eslint/promise-function-async
  async onError() {
    return new Promise((_resolve, reject) => {
      const handleError = (error) => {
        this.off("error", handleError);
        reject(error);
      };
      this.on("error", handleError);
    });
  }
  /**
  Size of the queue, the number of queued items waiting to run.
  */
  get size() {
    return __privateGet(this, _queue2).size;
  }
  /**
      Size of the queue, filtered by the given options.
  
      For example, this can be used to find the number of items remaining in the queue with a specific priority level.
      */
  sizeBy(options) {
    return __privateGet(this, _queue2).filter(options).length;
  }
  /**
  Number of running items (no longer in the queue).
  */
  get pending() {
    return __privateGet(this, _pending);
  }
  /**
  Whether the queue is currently paused.
  */
  get isPaused() {
    return __privateGet(this, _isPaused);
  }
  /**
  Whether the queue is currently rate-limited due to intervalCap.
  */
  get isRateLimited() {
    return __privateGet(this, _rateLimitedInInterval);
  }
  /**
      Whether the queue is saturated. Returns `true` when:
      - All concurrency slots are occupied and tasks are waiting, OR
      - The queue is rate-limited and tasks are waiting
  
      Useful for detecting backpressure and potential hanging tasks.
  
      ```js
      import PQueue from 'p-queue';
  
      const queue = new PQueue({concurrency: 2});
  
      // Backpressure handling
      if (queue.isSaturated) {
          console.log('Queue is saturated, waiting for capacity...');
          await queue.onSizeLessThan(queue.concurrency);
      }
  
      // Monitoring for stuck tasks
      setInterval(() => {
          if (queue.isSaturated) {
              console.warn(`Queue saturated: ${queue.pending} running, ${queue.size} waiting`);
          }
      }, 60000);
      ```
      */
  get isSaturated() {
    return __privateGet(this, _pending) === __privateGet(this, _concurrency) && __privateGet(this, _queue2).size > 0 || this.isRateLimited && __privateGet(this, _queue2).size > 0;
  }
  /**
      The tasks currently being executed. Each task includes its `id`, `priority`, `startTime`, and `timeout` (if set).
  
      Returns an array of task info objects.
  
      ```js
      import PQueue from 'p-queue';
  
      const queue = new PQueue({concurrency: 2});
  
      // Add tasks with IDs for better debugging
      queue.add(() => fetchUser(123), {id: 'user-123'});
      queue.add(() => fetchPosts(456), {id: 'posts-456', priority: 1});
  
      // Check what's running
      console.log(queue.runningTasks);
      // => [{
      //   id: 'user-123',
      //   priority: 0,
      //   startTime: 1759253001716,
      //   timeout: undefined
      // }, {
      //   id: 'posts-456',
      //   priority: 1,
      //   startTime: 1759253001916,
      //   timeout: undefined
      // }]
      ```
      */
  get runningTasks() {
    return [...__privateGet(this, _runningTasks).values()].map((task) => ({ ...task }));
  }
};
_carryoverIntervalCount = new WeakMap();
_isIntervalIgnored = new WeakMap();
_intervalCount = new WeakMap();
_intervalCap = new WeakMap();
_rateLimitedInInterval = new WeakMap();
_rateLimitFlushScheduled = new WeakMap();
_interval = new WeakMap();
_intervalEnd = new WeakMap();
_lastExecutionTime = new WeakMap();
_intervalId = new WeakMap();
_timeoutId = new WeakMap();
_queue2 = new WeakMap();
_queueClass = new WeakMap();
_pending = new WeakMap();
_concurrency = new WeakMap();
_isPaused = new WeakMap();
_idAssigner = new WeakMap();
_runningTasks = new WeakMap();
_PQueue_instances = new WeakSet();
doesIntervalAllowAnother_get = function() {
  return __privateGet(this, _isIntervalIgnored) || __privateGet(this, _intervalCount) < __privateGet(this, _intervalCap);
};
doesConcurrentAllowAnother_get = function() {
  return __privateGet(this, _pending) < __privateGet(this, _concurrency);
};
next_fn = function() {
  __privateWrapper(this, _pending)._--;
  if (__privateGet(this, _pending) === 0) {
    this.emit("pendingZero");
  }
  __privateMethod(this, _PQueue_instances, tryToStartAnother_fn).call(this);
  this.emit("next");
};
onResumeInterval_fn = function() {
  __privateMethod(this, _PQueue_instances, onInterval_fn).call(this);
  __privateMethod(this, _PQueue_instances, initializeIntervalIfNeeded_fn).call(this);
  __privateSet(this, _timeoutId, void 0);
};
isIntervalPaused_get = function() {
  const now = Date.now();
  if (__privateGet(this, _intervalId) === void 0) {
    const delay = __privateGet(this, _intervalEnd) - now;
    if (delay < 0) {
      if (__privateGet(this, _lastExecutionTime) > 0) {
        const timeSinceLastExecution = now - __privateGet(this, _lastExecutionTime);
        if (timeSinceLastExecution < __privateGet(this, _interval)) {
          __privateMethod(this, _PQueue_instances, createIntervalTimeout_fn).call(this, __privateGet(this, _interval) - timeSinceLastExecution);
          return true;
        }
      }
      __privateSet(this, _intervalCount, __privateGet(this, _carryoverIntervalCount) ? __privateGet(this, _pending) : 0);
    } else {
      __privateMethod(this, _PQueue_instances, createIntervalTimeout_fn).call(this, delay);
      return true;
    }
  }
  return false;
};
createIntervalTimeout_fn = function(delay) {
  if (__privateGet(this, _timeoutId) !== void 0) {
    return;
  }
  __privateSet(this, _timeoutId, setTimeout(() => {
    __privateMethod(this, _PQueue_instances, onResumeInterval_fn).call(this);
  }, delay));
};
clearIntervalTimer_fn = function() {
  if (__privateGet(this, _intervalId)) {
    clearInterval(__privateGet(this, _intervalId));
    __privateSet(this, _intervalId, void 0);
  }
};
clearTimeoutTimer_fn = function() {
  if (__privateGet(this, _timeoutId)) {
    clearTimeout(__privateGet(this, _timeoutId));
    __privateSet(this, _timeoutId, void 0);
  }
};
tryToStartAnother_fn = function() {
  if (__privateGet(this, _queue2).size === 0) {
    __privateMethod(this, _PQueue_instances, clearIntervalTimer_fn).call(this);
    this.emit("empty");
    if (__privateGet(this, _pending) === 0) {
      __privateMethod(this, _PQueue_instances, clearTimeoutTimer_fn).call(this);
      this.emit("idle");
    }
    return false;
  }
  let taskStarted = false;
  if (!__privateGet(this, _isPaused)) {
    const canInitializeInterval = !__privateGet(this, _PQueue_instances, isIntervalPaused_get);
    if (__privateGet(this, _PQueue_instances, doesIntervalAllowAnother_get) && __privateGet(this, _PQueue_instances, doesConcurrentAllowAnother_get)) {
      const job = __privateGet(this, _queue2).dequeue();
      if (!__privateGet(this, _isIntervalIgnored)) {
        __privateWrapper(this, _intervalCount)._++;
        __privateMethod(this, _PQueue_instances, scheduleRateLimitUpdate_fn).call(this);
      }
      this.emit("active");
      __privateSet(this, _lastExecutionTime, Date.now());
      job();
      if (canInitializeInterval) {
        __privateMethod(this, _PQueue_instances, initializeIntervalIfNeeded_fn).call(this);
      }
      taskStarted = true;
    }
  }
  return taskStarted;
};
initializeIntervalIfNeeded_fn = function() {
  if (__privateGet(this, _isIntervalIgnored) || __privateGet(this, _intervalId) !== void 0) {
    return;
  }
  __privateSet(this, _intervalId, setInterval(() => {
    __privateMethod(this, _PQueue_instances, onInterval_fn).call(this);
  }, __privateGet(this, _interval)));
  __privateSet(this, _intervalEnd, Date.now() + __privateGet(this, _interval));
};
onInterval_fn = function() {
  if (__privateGet(this, _intervalCount) === 0 && __privateGet(this, _pending) === 0 && __privateGet(this, _intervalId)) {
    __privateMethod(this, _PQueue_instances, clearIntervalTimer_fn).call(this);
  }
  __privateSet(this, _intervalCount, __privateGet(this, _carryoverIntervalCount) ? __privateGet(this, _pending) : 0);
  __privateMethod(this, _PQueue_instances, processQueue_fn).call(this);
  __privateMethod(this, _PQueue_instances, scheduleRateLimitUpdate_fn).call(this);
};
/**
Executes all queued functions until it reaches the limit.
*/
processQueue_fn = function() {
  while (__privateMethod(this, _PQueue_instances, tryToStartAnother_fn).call(this)) {
  }
};
onEvent_fn = async function(event, filter) {
  return new Promise((resolve) => {
    const listener = () => {
      if (filter && !filter()) {
        return;
      }
      this.off(event, listener);
      resolve();
    };
    this.on(event, listener);
  });
};
setupRateLimitTracking_fn = function() {
  if (__privateGet(this, _isIntervalIgnored)) {
    return;
  }
  this.on("add", () => {
    if (__privateGet(this, _queue2).size > 0) {
      __privateMethod(this, _PQueue_instances, scheduleRateLimitUpdate_fn).call(this);
    }
  });
  this.on("next", () => {
    __privateMethod(this, _PQueue_instances, scheduleRateLimitUpdate_fn).call(this);
  });
};
scheduleRateLimitUpdate_fn = function() {
  if (__privateGet(this, _isIntervalIgnored) || __privateGet(this, _rateLimitFlushScheduled)) {
    return;
  }
  __privateSet(this, _rateLimitFlushScheduled, true);
  queueMicrotask(() => {
    __privateSet(this, _rateLimitFlushScheduled, false);
    __privateMethod(this, _PQueue_instances, updateRateLimitState_fn).call(this);
  });
};
updateRateLimitState_fn = function() {
  const previous = __privateGet(this, _rateLimitedInInterval);
  const shouldBeRateLimited = !__privateGet(this, _isIntervalIgnored) && __privateGet(this, _intervalCount) >= __privateGet(this, _intervalCap) && __privateGet(this, _queue2).size > 0;
  if (shouldBeRateLimited !== previous) {
    __privateSet(this, _rateLimitedInInterval, shouldBeRateLimited);
    this.emit(shouldBeRateLimited ? "rateLimit" : "rateLimitCleared");
  }
};

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/cache.js
var SimpleTimeCache = class {
  constructor(options) {
    __publicField(this, "entries");
    __publicField(this, "validityMs");
    __publicField(this, "lastPruneTime", 0);
    this.entries = /* @__PURE__ */ new Map();
    this.validityMs = options.validityMs;
  }
  put(key, value) {
    this.entries.set(key, { value, validUntilMs: Date.now() + this.validityMs });
    this.prune();
  }
  prune() {
    const now = Date.now();
    if (now - this.lastPruneTime < 200) {
      return;
    }
    this.lastPruneTime = now;
    for (const [k, v] of this.entries.entries()) {
      if (v.validUntilMs < now) {
        this.entries.delete(k);
      } else {
        break;
      }
    }
  }
  has(key) {
    return this.entries.has(key);
  }
  get(key) {
    const value = this.entries.get(key);
    return value != null && value.validUntilMs >= Date.now() ? value.value : void 0;
  }
  clear() {
    this.entries = /* @__PURE__ */ new Map();
    this.lastPruneTime = 0;
  }
};

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/message/rpc.js
var RPC;
(function(RPC2) {
  let SubOpts;
  (function(SubOpts2) {
    let _codec2;
    SubOpts2.codec = () => {
      if (_codec2 == null) {
        _codec2 = message((obj, w, opts = {}) => {
          if (opts.lengthDelimited !== false) {
            w.fork();
          }
          if (obj.subscribe != null) {
            w.uint32(8);
            w.bool(obj.subscribe);
          }
          if (obj.topic != null) {
            w.uint32(18);
            w.string(obj.topic);
          }
          if (opts.lengthDelimited !== false) {
            w.ldelim();
          }
        }, (reader, length, opts = {}) => {
          const obj = {};
          const end = length == null ? reader.len : reader.pos + length;
          while (reader.pos < end) {
            const tag = reader.uint32();
            switch (tag >>> 3) {
              case 1: {
                obj.subscribe = reader.bool();
                break;
              }
              case 2: {
                obj.topic = reader.string();
                break;
              }
              default: {
                reader.skipType(tag & 7);
                break;
              }
            }
          }
          return obj;
        });
      }
      return _codec2;
    };
    SubOpts2.encode = (obj) => {
      return encodeMessage(obj, SubOpts2.codec());
    };
    SubOpts2.decode = (buf, opts) => {
      return decodeMessage(buf, SubOpts2.codec(), opts);
    };
  })(SubOpts = RPC2.SubOpts || (RPC2.SubOpts = {}));
  let Message;
  (function(Message2) {
    let _codec2;
    Message2.codec = () => {
      if (_codec2 == null) {
        _codec2 = message((obj, w, opts = {}) => {
          if (opts.lengthDelimited !== false) {
            w.fork();
          }
          if (obj.from != null) {
            w.uint32(10);
            w.bytes(obj.from);
          }
          if (obj.data != null) {
            w.uint32(18);
            w.bytes(obj.data);
          }
          if (obj.sequenceNumber != null) {
            w.uint32(26);
            w.bytes(obj.sequenceNumber);
          }
          if (obj.topic != null) {
            w.uint32(34);
            w.string(obj.topic);
          }
          if (obj.signature != null) {
            w.uint32(42);
            w.bytes(obj.signature);
          }
          if (obj.key != null) {
            w.uint32(50);
            w.bytes(obj.key);
          }
          if (opts.lengthDelimited !== false) {
            w.ldelim();
          }
        }, (reader, length, opts = {}) => {
          const obj = {};
          const end = length == null ? reader.len : reader.pos + length;
          while (reader.pos < end) {
            const tag = reader.uint32();
            switch (tag >>> 3) {
              case 1: {
                obj.from = reader.bytes();
                break;
              }
              case 2: {
                obj.data = reader.bytes();
                break;
              }
              case 3: {
                obj.sequenceNumber = reader.bytes();
                break;
              }
              case 4: {
                obj.topic = reader.string();
                break;
              }
              case 5: {
                obj.signature = reader.bytes();
                break;
              }
              case 6: {
                obj.key = reader.bytes();
                break;
              }
              default: {
                reader.skipType(tag & 7);
                break;
              }
            }
          }
          return obj;
        });
      }
      return _codec2;
    };
    Message2.encode = (obj) => {
      return encodeMessage(obj, Message2.codec());
    };
    Message2.decode = (buf, opts) => {
      return decodeMessage(buf, Message2.codec(), opts);
    };
  })(Message = RPC2.Message || (RPC2.Message = {}));
  let _codec;
  RPC2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.subscriptions != null) {
          for (const value of obj.subscriptions) {
            w.uint32(10);
            RPC2.SubOpts.codec().encode(value, w);
          }
        }
        if (obj.messages != null) {
          for (const value of obj.messages) {
            w.uint32(18);
            RPC2.Message.codec().encode(value, w);
          }
        }
        if (obj.control != null) {
          w.uint32(26);
          ControlMessage.codec().encode(obj.control, w);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        var _a2, _b2, _c2, _d2, _e2;
        const obj = {
          subscriptions: [],
          messages: []
        };
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              if (((_a2 = opts.limits) == null ? void 0 : _a2.subscriptions) != null && obj.subscriptions.length === opts.limits.subscriptions) {
                throw new MaxLengthError('Decode error - map field "subscriptions" had too many elements');
              }
              obj.subscriptions.push(RPC2.SubOpts.codec().decode(reader, reader.uint32(), {
                limits: (_b2 = opts.limits) == null ? void 0 : _b2.subscriptions$
              }));
              break;
            }
            case 2: {
              if (((_c2 = opts.limits) == null ? void 0 : _c2.messages) != null && obj.messages.length === opts.limits.messages) {
                throw new MaxLengthError('Decode error - map field "messages" had too many elements');
              }
              obj.messages.push(RPC2.Message.codec().decode(reader, reader.uint32(), {
                limits: (_d2 = opts.limits) == null ? void 0 : _d2.messages$
              }));
              break;
            }
            case 3: {
              obj.control = ControlMessage.codec().decode(reader, reader.uint32(), {
                limits: (_e2 = opts.limits) == null ? void 0 : _e2.control
              });
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  RPC2.encode = (obj) => {
    return encodeMessage(obj, RPC2.codec());
  };
  RPC2.decode = (buf, opts) => {
    return decodeMessage(buf, RPC2.codec(), opts);
  };
})(RPC || (RPC = {}));
var ControlMessage;
(function(ControlMessage2) {
  let _codec;
  ControlMessage2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.ihave != null) {
          for (const value of obj.ihave) {
            w.uint32(10);
            ControlIHave.codec().encode(value, w);
          }
        }
        if (obj.iwant != null) {
          for (const value of obj.iwant) {
            w.uint32(18);
            ControlIWant.codec().encode(value, w);
          }
        }
        if (obj.graft != null) {
          for (const value of obj.graft) {
            w.uint32(26);
            ControlGraft.codec().encode(value, w);
          }
        }
        if (obj.prune != null) {
          for (const value of obj.prune) {
            w.uint32(34);
            ControlPrune.codec().encode(value, w);
          }
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        var _a2, _b2, _c2, _d2, _e2, _f, _g, _h;
        const obj = {
          ihave: [],
          iwant: [],
          graft: [],
          prune: []
        };
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              if (((_a2 = opts.limits) == null ? void 0 : _a2.ihave) != null && obj.ihave.length === opts.limits.ihave) {
                throw new MaxLengthError('Decode error - map field "ihave" had too many elements');
              }
              obj.ihave.push(ControlIHave.codec().decode(reader, reader.uint32(), {
                limits: (_b2 = opts.limits) == null ? void 0 : _b2.ihave$
              }));
              break;
            }
            case 2: {
              if (((_c2 = opts.limits) == null ? void 0 : _c2.iwant) != null && obj.iwant.length === opts.limits.iwant) {
                throw new MaxLengthError('Decode error - map field "iwant" had too many elements');
              }
              obj.iwant.push(ControlIWant.codec().decode(reader, reader.uint32(), {
                limits: (_d2 = opts.limits) == null ? void 0 : _d2.iwant$
              }));
              break;
            }
            case 3: {
              if (((_e2 = opts.limits) == null ? void 0 : _e2.graft) != null && obj.graft.length === opts.limits.graft) {
                throw new MaxLengthError('Decode error - map field "graft" had too many elements');
              }
              obj.graft.push(ControlGraft.codec().decode(reader, reader.uint32(), {
                limits: (_f = opts.limits) == null ? void 0 : _f.graft$
              }));
              break;
            }
            case 4: {
              if (((_g = opts.limits) == null ? void 0 : _g.prune) != null && obj.prune.length === opts.limits.prune) {
                throw new MaxLengthError('Decode error - map field "prune" had too many elements');
              }
              obj.prune.push(ControlPrune.codec().decode(reader, reader.uint32(), {
                limits: (_h = opts.limits) == null ? void 0 : _h.prune$
              }));
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  ControlMessage2.encode = (obj) => {
    return encodeMessage(obj, ControlMessage2.codec());
  };
  ControlMessage2.decode = (buf, opts) => {
    return decodeMessage(buf, ControlMessage2.codec(), opts);
  };
})(ControlMessage || (ControlMessage = {}));
var ControlIHave;
(function(ControlIHave2) {
  let _codec;
  ControlIHave2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.topic != null) {
          w.uint32(10);
          w.string(obj.topic);
        }
        if (obj.messageIDs != null) {
          for (const value of obj.messageIDs) {
            w.uint32(18);
            w.bytes(value);
          }
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        var _a2;
        const obj = {
          messageIDs: []
        };
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              obj.topic = reader.string();
              break;
            }
            case 2: {
              if (((_a2 = opts.limits) == null ? void 0 : _a2.messageIDs) != null && obj.messageIDs.length === opts.limits.messageIDs) {
                throw new MaxLengthError('Decode error - map field "messageIDs" had too many elements');
              }
              obj.messageIDs.push(reader.bytes());
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  ControlIHave2.encode = (obj) => {
    return encodeMessage(obj, ControlIHave2.codec());
  };
  ControlIHave2.decode = (buf, opts) => {
    return decodeMessage(buf, ControlIHave2.codec(), opts);
  };
})(ControlIHave || (ControlIHave = {}));
var ControlIWant;
(function(ControlIWant2) {
  let _codec;
  ControlIWant2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.messageIDs != null) {
          for (const value of obj.messageIDs) {
            w.uint32(10);
            w.bytes(value);
          }
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        var _a2;
        const obj = {
          messageIDs: []
        };
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              if (((_a2 = opts.limits) == null ? void 0 : _a2.messageIDs) != null && obj.messageIDs.length === opts.limits.messageIDs) {
                throw new MaxLengthError('Decode error - map field "messageIDs" had too many elements');
              }
              obj.messageIDs.push(reader.bytes());
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  ControlIWant2.encode = (obj) => {
    return encodeMessage(obj, ControlIWant2.codec());
  };
  ControlIWant2.decode = (buf, opts) => {
    return decodeMessage(buf, ControlIWant2.codec(), opts);
  };
})(ControlIWant || (ControlIWant = {}));
var ControlGraft;
(function(ControlGraft2) {
  let _codec;
  ControlGraft2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.topic != null) {
          w.uint32(10);
          w.string(obj.topic);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        const obj = {};
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              obj.topic = reader.string();
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  ControlGraft2.encode = (obj) => {
    return encodeMessage(obj, ControlGraft2.codec());
  };
  ControlGraft2.decode = (buf, opts) => {
    return decodeMessage(buf, ControlGraft2.codec(), opts);
  };
})(ControlGraft || (ControlGraft = {}));
var ControlPrune;
(function(ControlPrune2) {
  let _codec;
  ControlPrune2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.topic != null) {
          w.uint32(10);
          w.string(obj.topic);
        }
        if (obj.peers != null) {
          for (const value of obj.peers) {
            w.uint32(18);
            PeerInfo.codec().encode(value, w);
          }
        }
        if (obj.backoff != null) {
          w.uint32(24);
          w.uint64(obj.backoff);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        var _a2, _b2;
        const obj = {
          peers: []
        };
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              obj.topic = reader.string();
              break;
            }
            case 2: {
              if (((_a2 = opts.limits) == null ? void 0 : _a2.peers) != null && obj.peers.length === opts.limits.peers) {
                throw new MaxLengthError('Decode error - map field "peers" had too many elements');
              }
              obj.peers.push(PeerInfo.codec().decode(reader, reader.uint32(), {
                limits: (_b2 = opts.limits) == null ? void 0 : _b2.peers$
              }));
              break;
            }
            case 3: {
              obj.backoff = reader.uint64();
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  ControlPrune2.encode = (obj) => {
    return encodeMessage(obj, ControlPrune2.codec());
  };
  ControlPrune2.decode = (buf, opts) => {
    return decodeMessage(buf, ControlPrune2.codec(), opts);
  };
})(ControlPrune || (ControlPrune = {}));
var PeerInfo;
(function(PeerInfo2) {
  let _codec;
  PeerInfo2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.peerID != null) {
          w.uint32(10);
          w.bytes(obj.peerID);
        }
        if (obj.signedPeerRecord != null) {
          w.uint32(18);
          w.bytes(obj.signedPeerRecord);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length, opts = {}) => {
        const obj = {};
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1: {
              obj.peerID = reader.bytes();
              break;
            }
            case 2: {
              obj.signedPeerRecord = reader.bytes();
              break;
            }
            default: {
              reader.skipType(tag & 7);
              break;
            }
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  PeerInfo2.encode = (obj) => {
    return encodeMessage(obj, PeerInfo2.codec());
  };
  PeerInfo2.decode = (buf, opts) => {
    return decodeMessage(buf, PeerInfo2.codec(), opts);
  };
})(PeerInfo || (PeerInfo = {}));

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/peer-streams.js
var PeerStreams = class extends TypedEventEmitter {
  constructor(peerId) {
    super();
    __publicField(this, "peerId");
    /**
     * An AbortController for controlled shutdown of the inbound stream
     */
    __publicField(this, "shutDownController");
    // messages sent by the remote
    __publicField(this, "inboundPb");
    // messages we send
    __publicField(this, "outboundPb");
    this.peerId = peerId;
    this.shutDownController = new AbortController();
  }
  attachInboundStream(stream, streamOpts) {
    this.inboundPb = pbStream(stream, streamOpts).pb(RPC);
    Promise.resolve().then(async () => {
      while (true) {
        if (this.inboundPb == null) {
          return;
        }
        const message2 = await this.inboundPb.read({
          signal: this.shutDownController.signal
        });
        this.safeDispatchEvent("message", {
          detail: message2
        });
      }
    }).catch((err) => {
      var _a2;
      (_a2 = this.inboundPb) == null ? void 0 : _a2.unwrap().unwrap().abort(err);
    });
  }
  attachOutboundStream(stream, streamOpts) {
    this.outboundPb = pbStream(stream, streamOpts).pb(RPC);
  }
  /**
   * Send a message to this peer
   */
  write(message2) {
    if (this.outboundPb == null) {
      return;
    }
    this.outboundPb.write(message2, {
      signal: this.shutDownController.signal
    }).catch((err) => {
      var _a2;
      (_a2 = this.outboundPb) == null ? void 0 : _a2.unwrap().unwrap().abort(err);
    });
  }
  /**
   * Closes the open connection to peer
   */
  close() {
    var _a2, _b2;
    this.shutDownController.abort();
    Promise.all([
      (_a2 = this.inboundPb) == null ? void 0 : _a2.unwrap().unwrap().close().catch((err) => {
        var _a3;
        (_a3 = this.inboundPb) == null ? void 0 : _a3.unwrap().unwrap().abort(err);
      }),
      (_b2 = this.outboundPb) == null ? void 0 : _b2.unwrap().unwrap().close().catch((err) => {
        var _a3;
        (_a3 = this.inboundPb) == null ? void 0 : _a3.unwrap().unwrap().abort(err);
      })
    ]).finally(() => {
      this.safeDispatchEvent("close");
    });
  }
};

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/utils.js
function randomSeqno() {
  return BigInt(`0x${toString(randomBytes(8), "base16")}`);
}
var msgId = (key, seqno) => {
  const seqnoBytes = fromString(seqno.toString(16).padStart(16, "0"), "base16");
  const keyBytes = publicKeyToProtobuf(key);
  const msgId2 = new Uint8Array(keyBytes.byteLength + seqnoBytes.length);
  msgId2.set(keyBytes, 0);
  msgId2.set(seqnoBytes, keyBytes.byteLength);
  return msgId2;
};
var noSignMsgId = (data) => {
  return sha256.encode(data);
};
var isSigned = async (message2) => {
  if (message2.sequenceNumber == null || message2.from == null || message2.signature == null) {
    return false;
  }
  const fromID = peerIdFromMultihash(decode(message2.from));
  if (fromID.publicKey != null) {
    return true;
  }
  if (message2.key != null) {
    const signingKey = message2.key;
    const signingID = peerIdFromPublicKey(publicKeyFromProtobuf(signingKey));
    return signingID.equals(fromID);
  }
  return false;
};
var toMessage = async (message2) => {
  if (message2.from == null) {
    throw new InvalidMessageError("RPC message was missing from");
  }
  if (!await isSigned(message2)) {
    return {
      type: "unsigned",
      topic: message2.topic ?? "",
      data: message2.data ?? new Uint8Array(0)
    };
  }
  const from = peerIdFromMultihash(decode(message2.from));
  const key = message2.key ?? from.publicKey;
  if (key == null) {
    throw new InvalidMessageError("RPC message was missing public key");
  }
  const msg = {
    type: "signed",
    from,
    topic: message2.topic ?? "",
    sequenceNumber: bigIntFromBytes(message2.sequenceNumber ?? new Uint8Array(0)),
    data: message2.data ?? new Uint8Array(0),
    signature: message2.signature ?? new Uint8Array(0),
    key: key instanceof Uint8Array ? publicKeyFromProtobuf(key) : key
  };
  return msg;
};
var toRpcMessage = (message2) => {
  if (message2.type === "signed") {
    return {
      from: message2.from.toMultihash().bytes,
      data: message2.data,
      sequenceNumber: bigIntToBytes(message2.sequenceNumber),
      topic: message2.topic,
      signature: message2.signature,
      key: message2.key ? publicKeyToProtobuf(message2.key) : void 0
    };
  }
  return {
    data: message2.data,
    topic: message2.topic
  };
};
var bigIntToBytes = (num) => {
  let str = num.toString(16);
  if (str.length % 2 !== 0) {
    str = `0${str}`;
  }
  return fromString(str, "base16");
};
var bigIntFromBytes = (num) => {
  return BigInt(`0x${toString(num, "base16")}`);
};

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/sign.js
var SignPrefix = fromString("libp2p-pubsub:");
async function signMessage(privateKey, message2, encode) {
  const outputMessage = {
    type: "signed",
    topic: message2.topic,
    data: message2.data,
    sequenceNumber: message2.sequenceNumber,
    from: peerIdFromPrivateKey(privateKey)
  };
  const bytes = concat([
    SignPrefix,
    encode(toRpcMessage(outputMessage)).subarray()
  ]);
  outputMessage.signature = await privateKey.sign(bytes);
  outputMessage.key = privateKey.publicKey;
  return outputMessage;
}
async function verifySignature(message2, encode) {
  if (message2.type !== "signed") {
    throw new Error('Message type must be "signed" to be verified');
  }
  if (message2.signature == null) {
    throw new Error("Message must contain a signature to be verified");
  }
  if (message2.from == null) {
    throw new Error("Message must contain a from property to be verified");
  }
  const bytes = concat([
    SignPrefix,
    encode({
      ...toRpcMessage(message2),
      signature: void 0,
      key: void 0
    }).subarray()
  ]);
  const pubKey = messagePublicKey(message2);
  return pubKey.verify(bytes, message2.signature);
}
function messagePublicKey(message2) {
  if (message2.type !== "signed") {
    throw new Error('Message type must be "signed" to have a public key');
  }
  if (message2.from == null) {
    throw new Error("Could not get the public key from the originator id");
  }
  if (message2.key != null) {
    return message2.key;
  }
  if (message2.from.publicKey != null) {
    return message2.from.publicKey;
  }
  throw new Error("Could not get the public key from the originator id");
}

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/floodsub.js
var _a, _b, _c, _d, _e;
var FloodSub = class extends (_e = TypedEventEmitter, _d = pubSubSymbol, _c = Symbol.toStringTag, _b = serviceCapabilities, _a = serviceDependencies, _e) {
  constructor(components, init) {
    super();
    __publicField(this, "log");
    __publicField(this, "started");
    /**
     * Map of topics to which peers are subscribed to
     */
    __publicField(this, "topics");
    /**
     * List of our subscriptions
     */
    __publicField(this, "subscriptions");
    /**
     * Map of peer streams
     */
    __publicField(this, "peers");
    /**
     * The signature policy to follow by default
     */
    __publicField(this, "globalSignaturePolicy");
    /**
     * If router can relay received messages, even if not subscribed
     */
    __publicField(this, "canRelayMessage");
    /**
     * if publish should emit to self, if subscribed
     */
    __publicField(this, "emitSelf");
    /**
     * Topic validator map
     *
     * Keyed by topic
     * Topic validators are functions with the following input:
     */
    __publicField(this, "topicValidators");
    __publicField(this, "queue");
    __publicField(this, "protocol");
    __publicField(this, "components");
    __publicField(this, "_registrarTopologyId");
    __publicField(this, "maxInboundStreams");
    __publicField(this, "maxOutboundStreams");
    __publicField(this, "seenCache");
    __publicField(this, _d, true);
    __publicField(this, _c, "@libp2p/floodsub");
    __publicField(this, _b, [
      "@libp2p/pubsub"
    ]);
    __publicField(this, _a, [
      "@libp2p/identify"
    ]);
    this.log = components.logger.forComponent("libp2p:floodsub");
    this.components = components;
    this.protocol = init.protocol ?? protocol;
    this.started = false;
    this.topics = /* @__PURE__ */ new Map();
    this.subscriptions = /* @__PURE__ */ new Set();
    this.peers = new PeerMap();
    this.globalSignaturePolicy = init.globalSignaturePolicy === "StrictNoSign" ? "StrictNoSign" : "StrictSign";
    this.canRelayMessage = init.canRelayMessage ?? true;
    this.emitSelf = init.emitSelf ?? false;
    this.topicValidators = /* @__PURE__ */ new Map();
    this.queue = new PQueue({
      concurrency: init.messageProcessingConcurrency ?? 10
    });
    this.maxInboundStreams = init.maxInboundStreams ?? 1;
    this.maxOutboundStreams = init.maxOutboundStreams ?? 1;
    this.seenCache = new SimpleTimeCache({
      validityMs: (init == null ? void 0 : init.seenTTL) ?? 3e4
    });
    this._onIncomingStream = this._onIncomingStream.bind(this);
    this._onPeerConnected = this._onPeerConnected.bind(this);
    this._onPeerDisconnected = this._onPeerDisconnected.bind(this);
  }
  // LIFECYCLE METHODS
  /**
   * Register the pubsub protocol onto the libp2p node.
   */
  async start() {
    if (this.started) {
      return;
    }
    this.log("starting");
    await this.components.registrar.handle(this.protocol, this._onIncomingStream, {
      maxInboundStreams: this.maxInboundStreams,
      maxOutboundStreams: this.maxOutboundStreams
    });
    this._registrarTopologyId = await this.components.registrar.register(this.protocol, {
      onConnect: this._onPeerConnected,
      onDisconnect: this._onPeerDisconnected
    });
    this.log("started");
    this.started = true;
  }
  /**
   * Unregister the pubsub protocol and the streams with other peers will be closed.
   */
  async stop() {
    if (!this.started) {
      return;
    }
    const registrar = this.components.registrar;
    if (this._registrarTopologyId != null) {
      registrar.unregister(this._registrarTopologyId);
    }
    await registrar.unhandle(this.protocol);
    this.log("stopping");
    for (const peerStreams of this.peers.values()) {
      peerStreams.close();
    }
    this.peers.clear();
    this.subscriptions = /* @__PURE__ */ new Set();
    this.started = false;
    this.log("stopped");
  }
  isStarted() {
    return this.started;
  }
  /**
   * On an inbound stream opened
   */
  _onIncomingStream(stream, connection) {
    const peerStreams = this.addPeer(connection.remotePeer, stream);
    peerStreams.attachInboundStream(stream);
  }
  /**
   * Registrar notifies an established connection with pubsub protocol
   */
  async _onPeerConnected(peerId, conn) {
    this.log("connected %p", peerId);
    if (conn.streams.find((stream2) => stream2.direction === "outbound" && stream2.protocol === this.protocol)) {
      this.log("outbound pubsub stream already present on connection from %p", peerId);
      return;
    }
    const stream = await conn.newStream(this.protocol);
    const peerStreams = this.addPeer(peerId, stream);
    peerStreams.attachOutboundStream(stream);
    this.send(peerId, {
      subscriptions: Array.from(this.subscriptions).map((sub) => sub.toString()),
      subscribe: true
    });
  }
  /**
   * Registrar notifies a closing connection with pubsub protocol
   */
  _onPeerDisconnected(peerId, conn) {
    this.log("connection ended %p", peerId);
    this._removePeer(peerId);
  }
  /**
   * Notifies the router that a peer has been connected
   */
  addPeer(peerId, stream) {
    const existing = this.peers.get(peerId);
    if (existing != null) {
      return existing;
    }
    this.log("new peer %p", peerId);
    const peerStreams = new PeerStreams(peerId);
    this.peers.set(peerId, peerStreams);
    peerStreams.addEventListener("message", (evt) => {
      const rpcMsg = evt.detail;
      const messages = [];
      for (const msg of rpcMsg.messages ?? []) {
        if (msg.from == null || msg.data == null || msg.topic == null) {
          this.log("message from %p was missing from, data or topic fields, dropping", peerId);
          continue;
        }
        messages.push({
          from: msg.from,
          data: msg.data,
          topic: msg.topic,
          sequenceNumber: msg.sequenceNumber ?? void 0,
          signature: msg.signature ?? void 0,
          key: msg.key ?? void 0
        });
      }
      this.processRpc(peerStreams, {
        subscriptions: (rpcMsg.subscriptions ?? []).map((sub) => ({
          subscribe: Boolean(sub.subscribe),
          topic: sub.topic ?? ""
        })),
        messages
      }).catch((err) => {
        this.log(err);
      });
    });
    peerStreams.addEventListener("close", () => this._removePeer(peerId), {
      once: true
    });
    return peerStreams;
  }
  /**
   * Notifies the router that a peer has been disconnected
   */
  _removePeer(peerId) {
    const peerStreams = this.peers.get(peerId);
    if (peerStreams == null) {
      return;
    }
    peerStreams.close();
    this.log("delete peer %p", peerId);
    this.peers.delete(peerId);
    for (const peers of this.topics.values()) {
      peers.delete(peerId);
    }
  }
  /**
   * Handles an rpc request from a peer
   */
  async processRpc(peerStream, rpc) {
    this.log("rpc from %p", peerStream.peerId);
    const { subscriptions, messages } = rpc;
    if (subscriptions != null && subscriptions.length > 0) {
      this.log("subscription update from %p", peerStream.peerId);
      subscriptions.forEach((subOpt) => {
        this.processRpcSubOpt(peerStream.peerId, subOpt);
      });
      super.dispatchEvent(new CustomEvent("subscription-change", {
        detail: {
          peerId: peerStream.peerId,
          subscriptions: subscriptions.map(({ topic, subscribe }) => ({
            topic: `${topic ?? ""}`,
            subscribe: Boolean(subscribe)
          }))
        }
      }));
    }
    if (messages != null && messages.length > 0) {
      this.log("messages from %p", peerStream.peerId);
      this.queue.addAll(messages.map((message2) => async () => {
        if (message2.topic == null || !this.subscriptions.has(message2.topic) && !this.canRelayMessage) {
          this.log("received message we didn't subscribe to. Dropping.");
          return false;
        }
        try {
          const msg = await toMessage(message2);
          await this.processMessage(peerStream.peerId, msg);
        } catch (err) {
          this.log.error("failed to queue messages from %p - %e", peerStream.peerId, err);
        }
      })).catch((err) => {
        this.log(err);
      });
    }
    return true;
  }
  /**
   * Handles a subscription change from a peer
   */
  processRpcSubOpt(id, subOpt) {
    const t = subOpt.topic;
    if (t == null) {
      return;
    }
    let topicSet = this.topics.get(t);
    if (topicSet == null) {
      topicSet = new PeerSet();
      this.topics.set(t, topicSet);
    }
    if (subOpt.subscribe === true) {
      topicSet.add(id);
    } else {
      topicSet.delete(id);
    }
  }
  /**
   * Handles a message from a peer
   */
  async processMessage(from, msg) {
    if (this.components.peerId.equals(from) && !this.emitSelf) {
      return;
    }
    const seqno = await this.getMsgId(msg);
    const msgIdStr = toString(seqno, "base64");
    if (this.seenCache.has(msgIdStr)) {
      return;
    }
    this.seenCache.put(msgIdStr, true);
    try {
      await this.validate(from, msg);
    } catch (err) {
      this.log("Message is invalid, dropping it. %O", err);
      return;
    }
    if (this.subscriptions.has(msg.topic)) {
      const isFromSelf = this.components.peerId.equals(from);
      if (!isFromSelf || this.emitSelf) {
        super.dispatchEvent(new CustomEvent("message", {
          detail: msg
        }));
      }
    }
    await this.publishMessage(from, msg);
  }
  /**
   * The default msgID implementation
   * Child class can override this.
   */
  getMsgId(msg) {
    const signaturePolicy = this.globalSignaturePolicy;
    switch (signaturePolicy) {
      case "StrictSign":
        if (msg.type !== "signed") {
          throw new InvalidMessageError('Message type should be "signed" when signature policy is StrictSign but it was not');
        }
        if (msg.sequenceNumber == null) {
          throw new InvalidMessageError("Need sequence number when signature policy is StrictSign but it was missing");
        }
        if (msg.key == null) {
          throw new InvalidMessageError("Need key when signature policy is StrictSign but it was missing");
        }
        return msgId(msg.key, msg.sequenceNumber);
      case "StrictNoSign":
        return noSignMsgId(msg.data);
      default:
        throw new InvalidMessageError("Cannot get message id: unhandled signature policy");
    }
  }
  /**
   * Encode RPC object into a Uint8Array.
   * This can be override to use a custom router protobuf.
   */
  encodeMessage(rpc) {
    return RPC.Message.encode(rpc);
  }
  /**
   * Send an rpc object to a peer
   */
  send(peer, data) {
    const { messages, subscriptions, subscribe } = data;
    this.sendRpc(peer, {
      subscriptions: (subscriptions ?? []).map((str) => ({ topic: str, subscribe: Boolean(subscribe) })),
      messages: (messages ?? []).map(toRpcMessage)
    });
  }
  /**
   * Send an rpc object to a peer
   */
  sendRpc(peer, rpc) {
    const peerStreams = this.peers.get(peer);
    if (peerStreams == null) {
      this.log.error("cannot send RPC to %p as there are no streams to it available", peer);
      return;
    }
    peerStreams.write(rpc);
  }
  /**
   * Validates the given message. The signature will be checked for authenticity.
   * Throws an error on invalid messages
   */
  async validate(from, message2) {
    const signaturePolicy = this.globalSignaturePolicy;
    switch (signaturePolicy) {
      case "StrictNoSign":
        if (message2.type !== "unsigned") {
          throw new InvalidMessageError('Message type should be "unsigned" when signature policy is StrictNoSign but it was not');
        }
        if (message2.signature != null) {
          throw new InvalidMessageError("StrictNoSigning: signature should not be present");
        }
        if (message2.key != null) {
          throw new InvalidMessageError("StrictNoSigning: key should not be present");
        }
        if (message2.sequenceNumber != null) {
          throw new InvalidMessageError("StrictNoSigning: seqno should not be present");
        }
        break;
      case "StrictSign":
        if (message2.type !== "signed") {
          throw new InvalidMessageError('Message type should be "signed" when signature policy is StrictSign but it was not');
        }
        if (message2.signature == null) {
          throw new InvalidMessageError("StrictSigning: Signing required and no signature was present");
        }
        if (message2.sequenceNumber == null) {
          throw new InvalidMessageError("StrictSigning: Signing required and no sequenceNumber was present");
        }
        if (!await verifySignature(message2, this.encodeMessage.bind(this))) {
          throw new InvalidMessageError("StrictSigning: Invalid message signature");
        }
        break;
      default:
        throw new InvalidMessageError("Cannot validate message: unhandled signature policy");
    }
    const validatorFn = this.topicValidators.get(message2.topic);
    if (validatorFn != null) {
      const result = await validatorFn(from, message2);
      if (result === TopicValidatorResult.Reject || result === TopicValidatorResult.Ignore) {
        throw new InvalidMessageError("Message validation failed");
      }
    }
  }
  /**
   * Normalizes the message and signs it, if signing is enabled.
   * Should be used by the routers to create the message to send.
   */
  async buildMessage(message2) {
    const signaturePolicy = this.globalSignaturePolicy;
    switch (signaturePolicy) {
      case "StrictSign":
        return signMessage(this.components.privateKey, message2, this.encodeMessage.bind(this));
      case "StrictNoSign":
        return Promise.resolve({
          type: "unsigned",
          ...message2
        });
      default:
        throw new InvalidMessageError("Cannot build message: unhandled signature policy");
    }
  }
  // API METHODS
  /**
   * Get a list of the peer-ids that are subscribed to one topic.
   */
  getSubscribers(topic) {
    if (!this.started) {
      throw new NotStartedError("not started yet");
    }
    if (topic == null) {
      throw new InvalidParametersError("Topic is required");
    }
    const peersInTopic = this.topics.get(topic.toString());
    if (peersInTopic == null) {
      return [];
    }
    return Array.from(peersInTopic.values());
  }
  /**
   * Publishes messages to all subscribed peers
   */
  async publish(topic, data) {
    if (!this.started) {
      throw new Error("Pubsub has not started");
    }
    const message2 = {
      from: this.components.peerId,
      topic,
      data: data ?? new Uint8Array(0),
      sequenceNumber: randomSeqno()
    };
    this.log("publish topic: %s from: %p data: %m", topic, message2.from, message2.data);
    const rpcMessage = await this.buildMessage(message2);
    let emittedToSelf = false;
    if (this.emitSelf) {
      if (this.subscriptions.has(topic)) {
        emittedToSelf = true;
        super.dispatchEvent(new CustomEvent("message", {
          detail: rpcMessage
        }));
      }
    }
    const result = await this.publishMessage(this.components.peerId, rpcMessage);
    if (emittedToSelf) {
      result.recipients = [...result.recipients, this.components.peerId];
    }
    return result;
  }
  /**
   * Overriding the implementation of publish should handle the appropriate algorithms for the publish/subscriber implementation.
   * For example, a Floodsub implementation might simply publish each message to each topic for every peer.
   *
   * `sender` might be this peer, or we might be forwarding a message on behalf of another peer, in which case sender
   * is the peer we received the message from, which may not be the peer the message was created by.
   */
  async publishMessage(from, message2) {
    const peers = this.getSubscribers(message2.topic);
    const recipients = [];
    if (peers == null || peers.length === 0) {
      this.log("no peers are subscribed to topic %s", message2.topic);
      return { recipients };
    }
    peers.forEach((id) => {
      if (this.components.peerId.equals(id)) {
        this.log("not sending message on topic %s to myself", message2.topic);
        return;
      }
      if (id.equals(from)) {
        this.log("not sending message on topic %s to sender %p", message2.topic, id);
        return;
      }
      this.log("publish msgs on topics %s %p", message2.topic, id);
      recipients.push(id);
      this.send(id, { messages: [message2] });
    });
    return { recipients };
  }
  /**
   * Subscribes to a given topic.
   */
  subscribe(topic) {
    if (!this.started) {
      throw new Error("Pubsub has not started");
    }
    if (this.subscriptions.has(topic)) {
      return;
    }
    this.log("subscribe to topic: %s", topic);
    this.subscriptions.add(topic);
    for (const peerId of this.peers.keys()) {
      this.send(peerId, {
        subscriptions: [
          topic
        ],
        subscribe: true
      });
    }
  }
  /**
   * Unsubscribe from the given topic
   */
  unsubscribe(topic) {
    if (!this.started) {
      throw new Error("Pubsub is not started");
    }
    if (!this.subscriptions.has(topic)) {
      return;
    }
    this.log("unsubscribe from %s", topic);
    this.subscriptions.delete(topic);
    for (const peerId of this.peers.keys()) {
      this.send(peerId, {
        subscriptions: [
          topic
        ],
        subscribe: false
      });
    }
  }
  /**
   * Get the list of topics which the peer is subscribed to.
   */
  getTopics() {
    if (!this.started) {
      throw new Error("Pubsub is not started");
    }
    return Array.from(this.subscriptions);
  }
  getPeers() {
    if (!this.started) {
      throw new Error("Pubsub is not started");
    }
    return Array.from(this.peers.keys());
  }
};

// ../../peercompute/node_modules/@libp2p/floodsub/dist/src/index.js
var protocol = "/floodsub/1.0.0";
var StrictSign = "StrictSign";
var StrictNoSign = "StrictNoSign";
var TopicValidatorResult;
(function(TopicValidatorResult2) {
  TopicValidatorResult2["Accept"] = "accept";
  TopicValidatorResult2["Ignore"] = "ignore";
  TopicValidatorResult2["Reject"] = "reject";
})(TopicValidatorResult || (TopicValidatorResult = {}));
function isPubSub(obj) {
  return Boolean(obj == null ? void 0 : obj[pubSubSymbol]);
}
function floodsub(init = {}) {
  return (components) => new FloodSub(components, init);
}
export {
  StrictNoSign,
  StrictSign,
  TopicValidatorResult,
  floodsub,
  isPubSub,
  protocol,
  pubSubSymbol
};
//# sourceMappingURL=@libp2p_floodsub.js.map
